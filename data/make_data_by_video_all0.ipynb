{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"2uhupjZzjjgb"},"outputs":[],"source":["#자체 데이터 제작에 쓰인 코드\n","#동영상 촬영 후 해당 동영상을 YOLO를 적용하여 bounding box 라벨 정보를 생성하고, 이를 검토하여 학습데이터로 활용\n","#라벨값은 다른 코드에서 수정"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19474,"status":"ok","timestamp":1738079059003,"user":{"displayName":"jh song","userId":"18282331936275536826"},"user_tz":-540},"id":"bIcwWmsKjpnn","outputId":"c1dcc27f-cb9a-4959-9ac7-ee980c899fa9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Po3GwxN7jppd"},"outputs":[],"source":["path = '/content/drive/MyDrive/Bigproject'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4968,"status":"ok","timestamp":1738079063963,"user":{"displayName":"jh song","userId":"18282331936275536826"},"user_tz":-540},"id":"SWP7-yYCjprk","outputId":"e36e06fb-199e-41b6-88b2-66861acc0a78"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.3.68-py3-none-any.whl.metadata (35 kB)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.10.0.84)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.5)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.6.85)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n","Downloading ultralytics-8.3.68-py3-none-any.whl (913 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m913.6/913.6 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n","Installing collected packages: ultralytics-thop, ultralytics\n","Successfully installed ultralytics-8.3.68 ultralytics-thop-2.0.14\n"]}],"source":["## colab에서 세션 재시작을 요구하는 팝업이 뜨면 재시작 누르세요.\n","!pip install ultralytics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t5w81CiqjoDa"},"outputs":[],"source":["import os\n","import shutil\n","import zipfile"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k4Dks4hhjvkJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738079083789,"user_tz":-540,"elapsed":19835,"user":{"displayName":"jh song","userId":"18282331936275536826"}},"outputId":"2db6aae3-fe4b-49f0-bbfb-650ac997e220"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file ✅ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"]}],"source":["import cv2\n","from ultralytics import YOLO"]},{"cell_type":"code","source":["import cv2\n","from google.colab.patches import cv2_imshow\n","from ultralytics import YOLO\n","import os\n","from tqdm import tqdm"],"metadata":{"id":"aCw0fW6uPaZ3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","from google.colab.patches import cv2_imshow\n","from ultralytics import YOLO\n","import os\n","from tqdm import tqdm\n","\n","# 모델 경로 설정 및 불러오기\n","model_path = '/content/drive/MyDrive/Bigproject/model/m/yolom_imgsz=750_a_epoch_best.pt'\n","model = YOLO(model_path)\n","\n","# 클래스 이름 설정\n","class_names = [\n","    \"bread\", \"snack\", \"coffee\", \"juice\", \"noodle\", \"seasoning\", \"shampoo\",\n","    \"soap\", \"bodywash\", \"moisturizer\", \"detergent\", \"toothpaste\", \"tata_salt\",\n","    \"cheese\", \"egg\", \"milk\", \"meat\", \"sausages\", \"beverage\", \"canned_food\",\n","    \"miscellaneous_item\", \"apple\", \"banana\", \"tomato\", \"cucumber\", \"carrot\"\n","]\n","\n","# 동영상 폴더 경로 설정\n","video_folder_path = '/content/drive/MyDrive/Bigproject/Video/train1'\n","video_files = [f for f in os.listdir(video_folder_path) if f.endswith(('.mp4', '.avi', '.mkv'))]  # 지원 파일 형식\n","\n","if not video_files:\n","    print(\"동영상 파일이 없습니다.\")\n","    exit()\n","\n","print(f\"🎥 총 {len(video_files)}개의 동영상을 처리합니다.\")\n","\n","# 이미지 확인 플래그 (True로 설정 시 감지된 이미지를 출력)\n","show_images = True\n","\n","for video_file in video_files:\n","    data_name = os.path.splitext(video_file)[0]  # 동영상 파일 이름에서 확장자 제거\n","    video_path = os.path.join(video_folder_path, video_file)\n","\n","    # 저장 폴더 설정\n","    base_save_path = f'/content/drive/MyDrive/Bigproject/data_make/{data_name}'\n","    label_save_path = f\"{base_save_path}/label\"\n","    image_save_path = f\"{base_save_path}/image\"\n","    imagecheck_save_path = f\"{base_save_path}/imagecheck\"\n","\n","    # 폴더 생성\n","    os.makedirs(label_save_path, exist_ok=True)\n","    os.makedirs(image_save_path, exist_ok=True)\n","    os.makedirs(imagecheck_save_path, exist_ok=True)\n","\n","    # 동영상 열기\n","    cap = cv2.VideoCapture(video_path)\n","    if not cap.isOpened():\n","        print(f\"❌ 동영상을 열 수 없습니다: {video_file}\")\n","        continue\n","\n","    # 동영상 총 프레임 수 계산\n","    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    print(f\"🎥 [{video_file}] 총 프레임 수: {total_frames}\")\n","\n","    frame_count = 0\n","\n","    # 진행률 표시를 위한 tqdm 설정\n","    progress_bar = tqdm(total=total_frames, desc=f\"🔄 {data_name} 진행률\")\n","\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        # YOLO 모델을 통해 객체 감지\n","        results = model(frame, conf=0.5, iou=0.45)\n","\n","        # 어노테이션 저장용 리스트\n","        annotations = []\n","\n","        # 감지된 객체가 포함된 이미지를 위한 복사본\n","        frame_with_boxes = frame.copy()\n","\n","        for r in results:\n","            for box in r.boxes:\n","                x1, y1, x2, y2 = map(int, box.xyxy[0])  # 바운딩 박스 좌표\n","                cls_id = int(box.cls[0])  # 클래스 ID\n","                conf = box.conf[0]  # 신뢰도 점수\n","\n","                # 이미지 크기 가져오기\n","                img_height, img_width = frame.shape[:2]\n","\n","                # 정규화된 좌표 계산 (YOLO 형식)\n","                x_center = ((x1 + x2) / 2) / img_width\n","                y_center = ((y1 + y2) / 2) / img_height\n","                width = (x2 - x1) / img_width\n","                height = (y2 - y1) / img_height\n","\n","                # 어노테이션 형식: class_id x_center y_center width height\n","                annotations.append(f\"{cls_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n","\n","                # 바운딩 박스 및 텍스트 추가\n","                label = f\"{class_names[cls_id]} ({conf:.2f})\"\n","                color = (0, 255, 0)  # 초록색\n","                cv2.rectangle(frame_with_boxes, (x1, y1), (x2, y2), color, 2)\n","                cv2.putText(frame_with_boxes, label, (x1, y1 - 10),\n","                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n","\n","        # 텍스트 파일로 어노테이션 저장\n","        if annotations:\n","            label_file_path = os.path.join(label_save_path, f\"{data_name}_frame_{frame_count:04d}.txt\")  # 라벨 파일\n","            with open(label_file_path, 'w') as f:\n","                f.write('\\n'.join(annotations))\n","\n","            # 라벨과 같은 이름으로 원본 이미지 저장\n","            image_file_path = os.path.join(image_save_path, f\"{data_name}_frame_{frame_count:04d}.jpg\")\n","            cv2.imwrite(image_file_path, frame)\n","\n","            # 감지된 객체를 표시한 이미지 저장\n","            imagecheck_file_path = os.path.join(imagecheck_save_path, f\"{data_name}_frame_{frame_count:04d}_check.jpg\")\n","            cv2.imwrite(imagecheck_file_path, frame_with_boxes)\n","\n","            # 주기적으로 이미지 확인\n","            if show_images and frame_count % 10 == 0:  # 10 프레임마다 출력\n","                print(f\"📸 Frame {frame_count}: 객체 표시 이미지\")\n","                cv2_imshow(frame_with_boxes)\n","\n","        # tqdm 진행률 업데이트\n","        progress_bar.update(1)\n","\n","        frame_count += 1\n","\n","    cap.release()\n","    progress_bar.close()\n","    print(f\"📂 [{data_name}] 모든 데이터가 {base_save_path}에 저장되었습니다.\")\n","\n","print(\"✅ 모든 동영상 처리가 완료되었습니다.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1Ov93iklzFU2Ov8eSWRwNZdwbWb0NZU30"},"id":"j9jK4jHgQKhX","executionInfo":{"status":"ok","timestamp":1738080563309,"user_tz":-540,"elapsed":1479218,"user":{"displayName":"jh song","userId":"18282331936275536826"}},"outputId":"952a96dd-26ab-4e41-b712-70032bceee07"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"11vhQXiLQKjN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CdXPXahhQKlb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ㅁㅁ"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":146},"id":"3pUa_jixQKnl","executionInfo":{"status":"error","timestamp":1738080563310,"user_tz":-540,"elapsed":26,"user":{"displayName":"jh song","userId":"18282331936275536826"}},"outputId":"b02db991-f99d-41ab-bf38-cc8e7474dc2a"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'ᄆᄆ' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-a9c0ea6d0198>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mㅁㅁ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'ᄆᄆ' is not defined"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4lCsQRyJjvl_"},"outputs":[],"source":["import cv2\n","from google.colab.patches import cv2_imshow\n","from ultralytics import YOLO\n","import os\n","from tqdm import tqdm\n","\n","# 모델 경로 설정 및 불러오기\n","model_path = '/content/drive/MyDrive/Bigproject/model/m/yolom_imgsz=750_a_epoch_best.pt'\n","model = YOLO(model_path)\n","\n","# 클래스 이름 설정\n","class_names = [\n","    \"bread\", \"snack\", \"coffee\", \"juice\", \"noodle\", \"seasoning\", \"shampoo\",\n","    \"soap\", \"bodywash\", \"moisturizer\", \"detergent\", \"toothpaste\", \"tata_salt\",\n","    \"cheese\", \"egg\", \"milk\", \"meat\", \"sausages\", \"beverage\", \"canned_food\",\n","    \"miscellaneous_item\", \"apple\", \"banana\", \"tomato\", \"cucumber\", \"carrot\"\n","]\n","\n","# 저장 폴더 및 데이터 이름 설정\n","data_name = 'poka'  # 데이터 이름\n","base_save_path = f'/content/drive/MyDrive/Bigproject/data_make/{data_name}'\n","label_save_path = f\"{base_save_path}/label\"\n","image_save_path = f\"{base_save_path}/image\"\n","imagecheck_save_path = f\"{base_save_path}/imagecheck\"\n","\n","# 폴더 생성\n","os.makedirs(label_save_path, exist_ok=True)\n","os.makedirs(image_save_path, exist_ok=True)\n","os.makedirs(imagecheck_save_path, exist_ok=True)\n","\n","# 동영상 파일 경로 설정\n","video_path = '/content/drive/MyDrive/Bigproject/Video/20250128_154552.mp4'\n","cap = cv2.VideoCapture(video_path)\n","\n","if not cap.isOpened():\n","    print(\"동영상을 열 수 없습니다.\")\n","    exit()\n","\n","# 동영상 총 프레임 수 계산\n","total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","print(f\"🎥 동영상 총 프레임 수: {total_frames}\")\n","\n","frame_count = 0\n","\n","# 진행률 표시를 위한 tqdm 설정\n","progress_bar = tqdm(total=total_frames, desc=\"🔄 진행률\")\n","\n","# 이미지 확인 플래그 (True로 설정 시 감지된 이미지를 출력)\n","show_images = True\n","\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    # YOLO 모델을 통해 객체 감지\n","    results = model(frame, conf=0.5, iou=0.45)\n","\n","    # 어노테이션 저장용 리스트\n","    annotations = []\n","\n","    # 감지된 객체가 포함된 이미지를 위한 복사본\n","    frame_with_boxes = frame.copy()\n","\n","    for r in results:\n","        for box in r.boxes:\n","            x1, y1, x2, y2 = map(int, box.xyxy[0])  # 바운딩 박스 좌표\n","            cls_id = int(box.cls[0])  # 클래스 ID\n","            conf = box.conf[0]  # 신뢰도 점수\n","\n","            # 이미지 크기 가져오기\n","            img_height, img_width = frame.shape[:2]\n","\n","            # 정규화된 좌표 계산 (YOLO 형식)\n","            x_center = ((x1 + x2) / 2) / img_width\n","            y_center = ((y1 + y2) / 2) / img_height\n","            width = (x2 - x1) / img_width\n","            height = (y2 - y1) / img_height\n","\n","            # 어노테이션 형식: class_id x_center y_center width height\n","            annotations.append(f\"{cls_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n","\n","            # 바운딩 박스 및 텍스트 추가\n","            label = f\"{class_names[cls_id]} ({conf:.2f})\"\n","            color = (0, 255, 0)  # 초록색\n","            cv2.rectangle(frame_with_boxes, (x1, y1), (x2, y2), color, 2)\n","            cv2.putText(frame_with_boxes, label, (x1, y1 - 10),\n","                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n","\n","    # 텍스트 파일로 어노테이션 저장\n","    if annotations:\n","        label_file_path = os.path.join(label_save_path, f\"{data_name}_frame_{frame_count:04d}.txt\")  # 라벨 파일\n","        with open(label_file_path, 'w') as f:\n","            f.write('\\n'.join(annotations))\n","\n","        # 라벨과 같은 이름으로 원본 이미지 저장\n","        image_file_path = os.path.join(image_save_path, f\"{data_name}_frame_{frame_count:04d}.jpg\")\n","        cv2.imwrite(image_file_path, frame)\n","\n","        # 감지된 객체를 표시한 이미지 저장\n","        imagecheck_file_path = os.path.join(imagecheck_save_path, f\"{data_name}_frame_{frame_count:04d}_check.jpg\")\n","        cv2.imwrite(imagecheck_file_path, frame_with_boxes)\n","\n","        # 주기적으로 이미지 확인\n","        if show_images and frame_count % 10 == 0:  # 10 프레임마다 출력\n","            print(f\"📸 Frame {frame_count}: 객체 표시 이미지\")\n","            cv2_imshow(frame_with_boxes)\n","\n","    # tqdm 진행률 업데이트\n","    progress_bar.update(1)\n","\n","    frame_count += 1\n","\n","cap.release()\n","progress_bar.close()\n","print(f\"📂 모든 데이터가 {base_save_path}에 저장되었습니다.\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"Cx6JFUuMPMCb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qtaeo8Y5PMEN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dad8KxTGPMGW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"k3F3dsIMPMIm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ㅁㅁ"],"metadata":{"id":"vysNUBJkPMK5"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oFZ2r7Yh3l8R"},"outputs":[],"source":["import cv2\n","from google.colab.patches import cv2_imshow\n","from ultralytics import YOLO\n","import os\n","\n","# 모델 경로 설정 및 불러오기\n","model_path = '/content/drive/MyDrive/Bigproject/model/m/yolom_imgsz=750_a_epoch_best.pt'\n","model = YOLO(model_path)\n","\n","# 클래스 이름 설정\n","class_names = [\n","    \"bread\", \"snack\", \"coffee\", \"juice\", \"noodle\", \"seasoning\", \"shampoo\",\n","    \"soap\", \"bodywash\", \"moisturizer\", \"detergent\", \"toothpaste\", \"tata_salt\",\n","    \"cheese\", \"egg\", \"milk\", \"meat\", \"sausages\", \"beverage\", \"canned_food\",\n","    \"miscellaneous_item\", \"apple\", \"banana\", \"tomato\", \"cucumber\", \"carrot\"\n","]\n","\n","# 저장 폴더 및 데이터 이름 설정\n","data_name = 'poka'  # 데이터 이름\n","base_save_path = f'/content/drive/MyDrive/Bigproject/data_make/{data_name}'\n","label_save_path = f\"{base_save_path}/label\"\n","image_save_path = f\"{base_save_path}/image\"\n","imagecheck_save_path = f\"{base_save_path}/imagecheck\"\n","\n","# 폴더 생성\n","os.makedirs(label_save_path, exist_ok=True)\n","os.makedirs(image_save_path, exist_ok=True)\n","os.makedirs(imagecheck_save_path, exist_ok=True)\n","\n","# 동영상 파일 경로 설정\n","#video_path = '/content/drive/MyDrive/Bigproject/Video/20250128_150638.mp4'\n","video_path = '/content/drive/MyDrive/Bigproject/Video/20250128_154552.mp4'\n","\n","cap = cv2.VideoCapture(video_path)\n","\n","if not cap.isOpened():\n","    print(\"동영상을 열 수 없습니다.\")\n","    exit()\n","\n","# 동영상 총 프레임 수 계산\n","total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","print(f\"🎥 동영상 총 프레임 수: {total_frames}\")\n","\n","frame_count = 0\n","\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    # YOLO 모델을 통해 객체 감지\n","    results = model(frame, conf=0.5, iou=0.45)\n","\n","    # 어노테이션 저장용 리스트\n","    annotations = []\n","\n","    # 감지된 객체가 포함된 이미지를 위한 복사본\n","    frame_with_boxes = frame.copy()\n","\n","    for r in results:\n","        for box in r.boxes:\n","            x1, y1, x2, y2 = map(int, box.xyxy[0])  # 바운딩 박스 좌표\n","            cls_id = int(box.cls[0])  # 클래스 ID\n","            conf = box.conf[0]  # 신뢰도 점수\n","\n","            # 이미지 크기 가져오기\n","            img_height, img_width = frame.shape[:2]\n","\n","            # 정규화된 좌표 계산 (YOLO 형식)\n","            x_center = ((x1 + x2) / 2) / img_width\n","            y_center = ((y1 + y2) / 2) / img_height\n","            width = (x2 - x1) / img_width\n","            height = (y2 - y1) / img_height\n","\n","            # 어노테이션 형식: class_id x_center y_center width height\n","            annotations.append(f\"{cls_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n","\n","            # 바운딩 박스 및 텍스트 추가\n","            label = f\"{class_names[cls_id]} ({conf:.2f})\"\n","            color = (0, 255, 0)  # 초록색\n","            cv2.rectangle(frame_with_boxes, (x1, y1), (x2, y2), color, 2)\n","            cv2.putText(frame_with_boxes, label, (x1, y1 - 10),\n","                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n","\n","    # 텍스트 파일로 어노테이션 저장\n","    if annotations:\n","        label_file_path = os.path.join(label_save_path, f\"{data_name}_frame_{frame_count:04d}.txt\")  # 라벨 파일\n","        with open(label_file_path, 'w') as f:\n","            f.write('\\n'.join(annotations))\n","\n","        # 라벨과 같은 이름으로 원본 이미지 저장\n","        image_file_path = os.path.join(image_save_path, f\"{data_name}_frame_{frame_count:04d}.jpg\")\n","        cv2.imwrite(image_file_path, frame)\n","\n","        # 감지된 객체를 표시한 이미지 저장\n","        imagecheck_file_path = os.path.join(imagecheck_save_path, f\"{data_name}_frame_{frame_count:04d}_check.jpg\")\n","        cv2.imwrite(imagecheck_file_path, frame_with_boxes)\n","\n","        # **Colab 출력 창에 감지된 객체 표시 이미지 출력**\n","        print(f\"📸 Frame {frame_count}: 객체 표시 이미지\")\n","        cv2_imshow(frame_with_boxes)\n","\n","    # 진행 상황 출력\n","    progress = (frame_count + 1) / total_frames * 100\n","    print(f\"🔄 진행률: {progress:.2f}% | Frame: {frame_count}/{total_frames} | 객체 감지: {len(annotations)}개\")\n","\n","    frame_count += 1\n","\n","cap.release()\n","print(f\"📂 모든 데이터가 {base_save_path}에 저장되었습니다.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AsZmpiqd3l-U"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bKj0r_sD3mAt"},"outputs":[],"source":["ㅁㅁ"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vgSl2wXTzov-"},"outputs":[],"source":["import cv2\n","from google.colab.patches import cv2_imshow\n","from ultralytics import YOLO\n","import os\n","\n","# 모델 경로 설정 및 불러오기\n","model_path = '/content/drive/MyDrive/Bigproject/model/m/yolom_imgsz=750_a_epoch_best.pt'\n","model = YOLO(model_path)\n","\n","# 클래스 이름 설정\n","class_names = [\n","    \"bread\", \"snack\", \"coffee\", \"juice\", \"noodle\", \"seasoning\", \"shampoo\",\n","    \"soap\", \"bodywash\", \"moisturizer\", \"detergent\", \"toothpaste\", \"tata_salt\",\n","    \"cheese\", \"egg\", \"milk\", \"meat\", \"sausages\", \"beverage\", \"canned_food\",\n","    \"miscellaneous_item\", \"apple\", \"banana\", \"tomato\", \"cucumber\", \"carrot\"\n","]\n","\n","# 저장 폴더 및 데이터 이름 설정\n","data_name = 'cookie'\n","base_save_path = f'/content/drive/MyDrive/Bigproject/data_make/{data_name}'\n","label_save_path = f\"{base_save_path}/label\"\n","image_save_path = f\"{base_save_path}/image\"\n","imagecheck_save_path = f\"{base_save_path}/imagecheck\"\n","\n","# 폴더 생성\n","os.makedirs(label_save_path, exist_ok=True)\n","os.makedirs(image_save_path, exist_ok=True)\n","os.makedirs(imagecheck_save_path, exist_ok=True)\n","\n","# 동영상 파일 경로 설정\n","video_path = '/content/drive/MyDrive/Bigproject/Video/20250128_150638.mp4'\n","cap = cv2.VideoCapture(video_path)\n","\n","if not cap.isOpened():\n","    print(\"동영상을 열 수 없습니다.\")\n","    exit()\n","\n","# 동영상 총 프레임 수 계산\n","total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","print(f\"🎥 동영상 총 프레임 수: {total_frames}\")\n","\n","frame_count = 0\n","\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    # YOLO 모델을 통해 객체 감지\n","    results = model(frame, conf=0.5, iou=0.45)\n","\n","    # 어노테이션 저장용 리스트\n","    annotations = []\n","\n","    # 감지된 객체가 포함된 이미지를 위한 복사본\n","    frame_with_boxes = frame.copy()\n","\n","    for r in results:\n","        for box in r.boxes:\n","            x1, y1, x2, y2 = map(int, box.xyxy[0])  # 바운딩 박스 좌표\n","            cls_id = int(box.cls[0])  # 클래스 ID\n","            conf = box.conf[0]  # 신뢰도 점수\n","\n","            # 이미지 크기 가져오기\n","            img_height, img_width = frame.shape[:2]\n","\n","            # 정규화된 좌표 계산 (YOLO 형식)\n","            x_center = ((x1 + x2) / 2) / img_width\n","            y_center = ((y1 + y2) / 2) / img_height\n","            width = (x2 - x1) / img_width\n","            height = (y2 - y1) / img_height\n","\n","            # 어노테이션 형식: class_id x_center y_center width height\n","            annotations.append(f\"{cls_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n","\n","            # 바운딩 박스 및 텍스트 추가\n","            label = f\"{class_names[cls_id]} ({conf:.2f})\"\n","            color = (0, 255, 0)  # 초록색\n","            cv2.rectangle(frame_with_boxes, (x1, y1), (x2, y2), color, 2)\n","            cv2.putText(frame_with_boxes, label, (x1, y1 - 10),\n","                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n","\n","    # 텍스트 파일로 어노테이션 저장\n","    if annotations:\n","        label_file_path = os.path.join(label_save_path, f\"frame_{frame_count:04d}.txt\")  # 라벨 파일\n","        with open(label_file_path, 'w') as f:\n","            f.write('\\n'.join(annotations))\n","\n","        # 라벨과 같은 이름으로 원본 이미지 저장\n","        image_file_path = os.path.join(image_save_path, f\"frame_{frame_count:04d}.jpg\")\n","        cv2.imwrite(image_file_path, frame)\n","\n","        # 감지된 객체를 표시한 이미지 저장\n","        imagecheck_file_path = os.path.join(imagecheck_save_path, f\"frame_{frame_count:04d}_check.jpg\")\n","        cv2.imwrite(imagecheck_file_path, frame_with_boxes)\n","\n","        # **Colab 출력 창에 감지된 객체 표시 이미지 출력**\n","        print(f\"📸 Frame {frame_count}: 객체 표시 이미지\")\n","        cv2_imshow(frame_with_boxes)\n","\n","    # 진행 상황 출력\n","    progress = (frame_count + 1) / total_frames * 100\n","    print(f\"🔄 진행률: {progress:.2f}% | Frame: {frame_count}/{total_frames} | 객체 감지: {len(annotations)}개\")\n","\n","    frame_count += 1\n","\n","cap.release()\n","print(f\"📂 모든 데이터가 {base_save_path}에 저장되었습니다.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zI6fQnUNzoyG"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7I-0-73gzo0S"},"outputs":[],"source":["ㅁㅁ"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aJ5c-FjRzo2l"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Duk5SPiUnJtt"},"outputs":[],"source":["import cv2\n","from google.colab.patches import cv2_imshow\n","from ultralytics import YOLO\n","import os\n","\n","# 모델 경로 설정 및 불러오기\n","model_path = '/content/drive/MyDrive/Bigproject/model/m/yolom_imgsz=750_a_epoch_best.pt'\n","model = YOLO(model_path)\n","\n","# 클래스 이름 설정\n","class_names = [\n","    \"bread\", \"snack\", \"coffee\", \"juice\", \"noodle\", \"seasoning\", \"shampoo\",\n","    \"soap\", \"bodywash\", \"moisturizer\", \"detergent\", \"toothpaste\", \"tata_salt\",\n","    \"cheese\", \"egg\", \"milk\", \"meat\", \"sausages\", \"beverage\", \"canned_food\",\n","    \"miscellaneous_item\", \"apple\", \"banana\", \"tomato\", \"cucumber\", \"carrot\"\n","]\n","\n","# 저장 폴더 및 데이터 이름 설정\n","data_name = 'cookie'\n","base_save_path = f'/content/drive/MyDrive/Bigproject/data_make/{data_name}'\n","label_save_path = f\"{base_save_path}/label\"\n","image_save_path = f\"{base_save_path}/image\"\n","imagecheck_save_path = f\"{base_save_path}/imagecheck\"\n","\n","# 폴더 생성\n","os.makedirs(label_save_path, exist_ok=True)\n","os.makedirs(image_save_path, exist_ok=True)\n","os.makedirs(imagecheck_save_path, exist_ok=True)\n","\n","# 동영상 파일 경로 설정\n","video_path = '/content/drive/MyDrive/Bigproject/Video/20250128_150638.mp4'\n","cap = cv2.VideoCapture(video_path)\n","\n","if not cap.isOpened():\n","    print(\"동영상을 열 수 없습니다.\")\n","    exit()\n","\n","# 동영상 총 프레임 수 계산\n","total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","print(f\"🎥 동영상 총 프레임 수: {total_frames}\")\n","\n","frame_count = 0\n","\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    # YOLO 모델을 통해 객체 감지\n","    results = model(frame, conf=0.5, iou=0.45)\n","\n","    # 어노테이션 저장용 리스트\n","    annotations = []\n","\n","    # 감지된 객체가 포함된 이미지를 위한 복사본\n","    frame_with_boxes = frame.copy()\n","\n","    for r in results:\n","        for box in r.boxes:\n","            x1, y1, x2, y2 = map(int, box.xyxy[0])  # 바운딩 박스 좌표\n","            cls_id = int(box.cls[0])  # 클래스 ID\n","            conf = box.conf[0]  # 신뢰도 점수\n","\n","            # 이미지 크기 가져오기\n","            img_height, img_width = frame.shape[:2]\n","\n","            # 정규화된 좌표 계산 (YOLO 형식)\n","            x_center = ((x1 + x2) / 2) / img_width\n","            y_center = ((y1 + y2) / 2) / img_height\n","            width = (x2 - x1) / img_width\n","            height = (y2 - y1) / img_height\n","\n","            # 어노테이션 형식: class_id x_center y_center width height\n","            annotations.append(f\"{cls_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n","\n","            # 바운딩 박스 및 텍스트 추가\n","            label = f\"{class_names[cls_id]} ({conf:.2f})\"\n","            color = (0, 255, 0)  # 초록색\n","            cv2.rectangle(frame_with_boxes, (x1, y1), (x2, y2), color, 2)\n","            cv2.putText(frame_with_boxes, label, (x1, y1 - 10),\n","                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n","\n","    # 텍스트 파일로 어노테이션 저장\n","    if annotations:\n","        label_file_path = os.path.join(label_save_path, f\"frame_{frame_count:04d}.txt\")  # 라벨 파일\n","        with open(label_file_path, 'w') as f:\n","            f.write('\\n'.join(annotations))\n","\n","        # 라벨과 같은 이름으로 원본 이미지 저장\n","        image_file_path = os.path.join(image_save_path, f\"frame_{frame_count:04d}.jpg\")\n","        cv2.imwrite(image_file_path, frame)\n","\n","        # 감지된 객체를 표시한 이미지 저장\n","        imagecheck_file_path = os.path.join(imagecheck_save_path, f\"frame_{frame_count:04d}_check.jpg\")\n","        cv2.imwrite(imagecheck_file_path, frame_with_boxes)\n","\n","    # 진행 상황 출력\n","    progress = (frame_count + 1) / total_frames * 100\n","    print(f\"🔄 진행률: {progress:.2f}% | Frame: {frame_count}/{total_frames} | 객체 감지: {len(annotations)}개\")\n","\n","    frame_count += 1\n","\n","cap.release()\n","print(f\"📂 모든 데이터가 {base_save_path}에 저장되었습니다.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oORoySORnJwd"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iYH4aaHpnJyx"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ak2ZbtcfjoQq"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPtmbkr4D1l1XSxYVaoYcZM"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}